# 文脈推定チャットデモ（Context Inference Chat Demo）
本リポジトリは、日本語対話における文脈理解を 統計的言語モデルや大規模言語モデル（LLM）に依存せず、明示的な推論段階（stage1〜5）によって扱う疑似体験型チャットデモである。

日常会話において人間が無意識に行っている「文脈の補完」「意図の推定」「責任や判断主体の推論」を、論理設計として分解・実装し、その推論過程を可視化することを目的としている。

---

## 研究の背景と目的
日本語の対話では、発話内容そのものよりも前提・暗黙の期待・感情・判断の委ね方などが意味理解に大きく影響する。

本研究では、以下を目的とする。

- 統計や学習に依存しない小規模な文脈推定設計の検証
- 文脈ズレが生じる構造を論理的に分解すること
- 推論結果だけでなく、推論過程そのものを提示すること

特定の語彙や表現構造を検出することで、各文脈タイプへの推論可能性を段階的に評価する。

本デモは、精度競争を目的とするものではなく、**「どのように文脈理解が成立するか」を説明可能な形で示す**基礎的な実証である。

---

## 文脈タイプの分類
本研究では、文脈のズレを以下の3タイプに分類する。

- **A：日常のすれ違い型**  
  前提や期待の共有不足によって生じる解釈のズレ

- **B：感情・含み型**  
  感情的含意、態度、含み表現によって意図が曖昧になる文脈

- **C：判断委ね型**  
  判断や責任の所在が明示されず、相手や状況に委ねられる文脈

**B：感情・含み系（Implicit / Affective Context）**
本デモでは、発話に含まれる評価・態度・感情の表出の強さに応じて、Bタイプを以下の2段階に分けて扱う。

⸻

**B（弱）：含意優位型（Implicit-dominant）**

発話の中に推測・含意・距離感を示す表現が含まれるが、
明確な感情語や態度表明が検出されない文脈。
-  	含意はあるが、話者の感情的立場は確定しない
-	文脈次第で A / B のどちらにも解釈可能
-	本デモでは「感情の方向性が弱い」状態として扱う

例：
-	「そういうのもいいと思います」
-	「まあ、悪くはないですね」
-	「それも一つの考え方ですね」

⸻

**B（強）：感情併存型（Implicit + Affective）**

含意表現に加えて、感情語・評価語・態度を示す語彙が検出される文脈。
-	含みと同時に、話者の感情的スタンスが推定可能
-	不満・遠慮・強がりなどが明示的に示唆される
-	本デモでは Bタイプとして確定分類される

例：
-	「別にいいですけど、時間かかりますよ」
-	「まあ大丈夫です（少し疲れた様子で）」
-	「さすがですね、本当に」


各分類の詳細定義および例文については  
`docs/context_types.md` を参照されたい。

---

## 推論段階（stage1〜5）

文脈理解は一括処理せず、以下の段階的推論として実装している。

- **stage1：基本的な文脈推定**  
  発話の表層構造と明示情報の把握

- **stage2：最小限の聞き返し**  
  情報不足や曖昧性の検出

- **stage3：因果関係推定**  
  発話が生じた背景や動機の推定

- **stage4：修飾構造の理解**  
  評価語・態度表現・緩和表現の解釈

- **stage5：名詞間の格関係推定**  
  行為主体・判断主体・責任の所在の確定

これらの段階を通じて、最終的な文脈タイプを分類する。

本デモでは「常に正しい分類」を目的とせず、文脈情報の不足によって生じる分類の不確定性も含めて、推論過程を観察・説明することを目的としています。

詳細な設計思想は `docs/stage_design.md` に記載している。

---

## デモについて

本デモは Streamlit を用いたチャット形式で実装されている。

ユーザーが任意の文を入力すると、

1. stage1〜5 に基づく推論
2. 文脈タイプの分類
3. 推論理由の提示

が行われる。

これにより、**「AIが何をどう考えてその解釈に至ったか」**を疑似体験的に確認できる。

---

## 使い方

```bash
pip install streamlitstreamlit run streamlit_app.py