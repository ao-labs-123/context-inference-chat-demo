# 文脈推定チャットデモ（Context Inference Chat Demo）
本リポジトリは、日本語対話における文脈理解を統計的言語モデルや大規模言語モデル（LLM）に依存せず、明示的な推論段階（stage1〜5）によって扱う疑似体験型チャットデモである。

日常会話において人間が無意識に行っている「文脈の補完」「意図の推定」「責任や判断主体の推論」を、論理設計として分解・実装し、その推論過程を可視化することを目的としている。

---

## 研究の背景と目的
日本語の対話では、発話内容そのものよりも前提・暗黙の期待・感情・判断の委ね方などが意味理解に大きく影響する。

本研究では、以下を目的とする。

- 統計や学習に依存しない小規模な文脈推定設計の検証
- 文脈ズレが生じる構造を論理的に分解すること
- 推論結果だけでなく、推論過程そのものを提示すること

本デモは、精度競争を目的とするものではなく、**「どのように文脈理解が成立するか」を説明可能な形で示す**基礎的な実証である。

---

## 文脈タイプの分類
本研究では、文脈のズレを以下の3タイプに分類する。

- **A：日常のすれ違い型**  
  前提や期待の共有不足によって生じる解釈のズレ

- **B：感情・含み型**  
  感情的含意、態度、含み表現によって意図が曖昧になる文脈

- **C：判断委ね型**  
  判断や責任の所在が明示されず、相手や状況に委ねられる文脈

各分類の詳細定義および例文については  
`docs/context_types.md` を参照されたい。

---

## 推論段階（stage1〜5）
文脈理解は一括処理せず、以下の段階的推論として実装している。

- **stage1：基本的な文脈推定**  
  発話の表層構造と明示情報の把握

- **stage2：最小限の聞き返し**  
  情報不足や曖昧性の検出

- **stage3：因果関係推定**  
  発話が生じた背景や動機の推定

- **stage4：修飾構造の理解**  
  評価語・態度表現・緩和表現の解釈

- **stage5：名詞間の格関係推定**  
  行為主体・判断主体・責任の所在の確定

これらの段階を通じて、最終的な文脈タイプを分類する。

詳細な設計思想は `docs/stage_design.md` に記載している。

---

## デモについて
本デモは Streamlit を用いたチャット形式で実装されている。

ユーザーが任意の文を入力すると、

1. stage1〜5 に基づく推論
2. 文脈タイプの分類
3. 推論理由の提示

が行われる。

これにより、**「AIが何をどう考えてその解釈に至ったか」**を疑似体験的に確認できる。

---

想定される応用例

	•	統計モデルを用いにくい小規模AI（家電、カーナビ等）
	•	文脈ズレの少ない対話型システム
	•	AI対話を用いたゲームにおけるログ保持・文脈管理
	•	説明可能AIの基礎設計検討

本デモ自体はアプリケーション実装を目的とせず、基礎論理の検証を主眼としている。

⸻

制限事項

	•	日本語対話に特化している
	•	皮肉・嫌味などの高度な語用論表現は限定的である
	•	統計的評価は今後の課題とする

ライセンス
MIT License

## 使い方
```bash
pip install streamlit
streamlit run streamlit_app.py
